{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "baafa886-a378-4cd8-a795-bc61777adf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '..'\n",
    "DATA_SOURCE = f'{PATH}/data/source'\n",
    "DATA_PROCESSED = f'{PATH}/data/processed'\n",
    "DATA_MODELS = f'{PATH}/models'\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = 'cpu'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e9af2d2-4759-45c0-8a4a-dccb921243c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from typing import Iterable, Dict\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d78dc7b1-03c5-44a2-93f6-b2d5584c44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
    "        mean_embeddings = sum_embeddings/sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class ColBERT(nn.Module):\n",
    "    def __init__(self, bert, dim=768, add_pooling=False):\n",
    "        super(ColBERT, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.fc = nn.Linear(dim*2**add_pooling, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.pooling = MeanPooling()\n",
    "        self.add_pooling = add_pooling\n",
    "        \n",
    "    def forward(self, query, document):\n",
    "        query_embedding = self.bert(**query)[0][:, 0, :]\n",
    "        document_embedding = self.bert(**document)[0][:, 0, :]\n",
    "        interaction = torch.mul(query_embedding, document_embedding)\n",
    "        \n",
    "        if self.add_pooling:\n",
    "            output = self.bert(**document)\n",
    "            pooling = self.pooling(output['last_hidden_state'], document['attention_mask'])\n",
    "            emb = torch.cat((interaction,pooling), -1)\n",
    "        else:\n",
    "            emb = interaction\n",
    "        scores = self.fc(emb)\n",
    "        relevance_scores = self.sigmoid(scores).squeeze()\n",
    "        return relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82ad42d9-a6a1-4697-8080-29c6d76c637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, query, document, relevance=None, cluster=None, max_length=128):\n",
    "        self.len = len(query)\n",
    "        self.query = tokenizer.batch_encode_plus(\n",
    "            list(query), \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=max_length\n",
    "        )\n",
    "        self.document = tokenizer.batch_encode_plus(\n",
    "            list(document), \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=max_length\n",
    "        )        \n",
    "        if relevance is not None:\n",
    "            self.relevance = torch.tensor(list(relevance))\n",
    "        else:\n",
    "            self.relevance = torch.tensor(np.ones(len(query)))\n",
    "        if cluster is not None:\n",
    "            self.cluster = torch.tensor(list(cluster))\n",
    "        else:\n",
    "            self.cluster = torch.tensor(np.ones(len(query)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query = dict(\n",
    "            input_ids=self.query['input_ids'][idx],\n",
    "            attention_mask=self.query['attention_mask'][idx],\n",
    "        )\n",
    "        document = dict(\n",
    "            input_ids=self.document['input_ids'][idx],\n",
    "            attention_mask=self.document['attention_mask'][idx],\n",
    "        )\n",
    "        relevance = self.relevance[idx]        \n",
    "        return dict(\n",
    "            query = query,\n",
    "            document = document,\n",
    "            relevance = relevance,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7535309e-2c57-478d-a85e-c036d0283b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(sentences, batch_size):\n",
    "    n_samples = len(sentences)\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        yield sentences[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36b85d27-d771-4454-b757-3bff94794a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny2')\n",
    "model = torch.load(f'{DATA_MODELS}/rubert-tiny2_1.pt')\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b929d2d6-b38c-49d5-810f-37d1096f261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'{DATA_PROCESSED}/df.pickle')\n",
    "df = df.query('split == \"test\"').reset_index(drop=True)\n",
    "\n",
    "ds = TextDataset(\n",
    "    tokenizer, \n",
    "    query=df['description_sorted_vacancy'], \n",
    "    document=df['description_sorted_resume'], \n",
    "    max_length=MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460e058-8573-4974-a122-416d18afe1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    df['predict_proba'] = np.concatenate([\n",
    "        model(\n",
    "            {k: v.to(DEVICE) for k, v in batch['query'].items()}, \n",
    "            {k: v.to(DEVICE) for k, v in batch['document'].items()}\n",
    "        ).cpu().numpy().squeeze() \n",
    "        for batch in batch_generator(ds, 10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a17ec8-4cb9-4f4f-b3b0-a4ea0f22ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = ['uuid_vacancy', 'uuid_resume', 'rank', 'label']\n",
    "df['rank'] = df.groupby('uuid_vacancy')['predict_proba'].rank(method='first', ascending=False).astype(int)\n",
    "df = df.sort_values('rank')\n",
    "df['label'] = df.eval('predict_proba > 0.45').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2353276-0e39-459d-b554-983d1be627d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522123893805309"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "356e8979-31a3-4df5-892c-2a4dd76ed985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid_vacancy</th>\n",
       "      <th>uuid_resume</th>\n",
       "      <th>rank</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>ebcd86ef-6e1f-39cf-8af3-85adaec6d3b3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>2444cdfb-370c-3f84-b97b-9462255688f2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>ff2a61d1-b70b-352b-8f08-ebc0a84de7ca</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>73592479-12bf-38d4-84f0-91fe33518b47</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>fd0ccbd0-3a58-3818-8691-98f31de17527</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>fd9c4130-177f-3546-8974-189a52fcc496</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>6065ee07-4c42-3cf4-8e45-9d053b9041f7</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>53a2a38b-4fef-3d65-8d6d-818d5e80dbfa</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>e59d1c07-489b-3299-803f-5dea7da43b56</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8b9c8d16-c7f0-38a2-b80c-d94030c15a6f</td>\n",
       "      <td>1f1809fd-fde5-3720-a5dc-02f1160f53a9</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             uuid_vacancy  \\\n",
       "37   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "29   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "62   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "20   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "73   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "..                                    ...   \n",
       "64   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "92   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "33   8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "104  8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "107  8b9c8d16-c7f0-38a2-b80c-d94030c15a6f   \n",
       "\n",
       "                              uuid_resume  rank  label  \n",
       "37   ebcd86ef-6e1f-39cf-8af3-85adaec6d3b3     1      1  \n",
       "29   2444cdfb-370c-3f84-b97b-9462255688f2     2      1  \n",
       "62   ff2a61d1-b70b-352b-8f08-ebc0a84de7ca     3      1  \n",
       "20   73592479-12bf-38d4-84f0-91fe33518b47     4      1  \n",
       "73   fd0ccbd0-3a58-3818-8691-98f31de17527     5      1  \n",
       "..                                    ...   ...    ...  \n",
       "64   fd9c4130-177f-3546-8974-189a52fcc496   109      0  \n",
       "92   6065ee07-4c42-3cf4-8e45-9d053b9041f7   110      0  \n",
       "33   53a2a38b-4fef-3d65-8d6d-818d5e80dbfa   111      0  \n",
       "104  e59d1c07-489b-3299-803f-5dea7da43b56   112      0  \n",
       "107  1f1809fd-fde5-3720-a5dc-02f1160f53a9   113      0  \n",
       "\n",
       "[113 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[clms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b3eecbe-72f1-4f6f-bc6c-b5c3e1ac7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[clms].to_excel(f'{DATA_PROCESSED}/result.xlsx', index=False)\n",
    "df[clms].to_csv(f'{DATA_PROCESSED}/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe02ae3-bd4c-4876-9187-d3ed15c4e396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml38",
   "language": "python",
   "name": "ml38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
